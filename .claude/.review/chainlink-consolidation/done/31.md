# Issue #31: Extend Dataset class to load from ATProto records

## Verdict: CLOSE

## Evidence
The Dataset class can now load from ATProto records through three mechanisms: (1) `DatasetLoader.to_dataset()` creates a `Dataset[ST]` from an AT URI by resolving storage type and constructing the appropriate URL, (2) `load_dataset()` with AT URI support (`at://...`) handles the full resolution pipeline including schema decoding for dynamic type generation, and (3) `BlobSource` enables streaming of PDS blob-stored shards as a `DataSource` implementation. The `_resolve_at_uri()` function handles all storage types (blobs, HTTP, S3, legacy external), creates the appropriate data source, and optionally decodes the schema to reconstruct the sample type dynamically via `schema_to_type()`.

## Codebase References
- `src/atdata/atmosphere/records.py` lines 700-749 -- `DatasetLoader.to_dataset()` creates Dataset from ATProto record
- `src/atdata/_hf_api.py` lines 494-591 -- `_resolve_at_uri()` full AT URI resolution
- `src/atdata/_hf_api.py` lines 538-549 -- blob storage resolution creating `BlobSource`
- `src/atdata/_hf_api.py` lines 550-566 -- HTTP and S3 storage resolution creating `URLSource`
- `src/atdata/_hf_api.py` lines 576-584 -- schema decoding via `SchemaLoader` + `schema_to_type()`
- `src/atdata/_hf_api.py` lines 867-877 -- `load_dataset()` AT URI entry point
- `src/atdata/_sources.py` lines 352-522 -- `BlobSource` class with PDS endpoint resolution, shard streaming, and `open_shard()`
- `src/atdata/_sources.py` lines 384-408 -- `_resolve_pds_endpoint()` with caching
- `src/atdata/_sources.py` lines 423-444 -- `BlobSource.shards` property yielding (at_uri, stream) pairs
- `src/atdata/_schema_codec.py` lines 234-334 -- `schema_to_type()` dynamic type generation from schema records
